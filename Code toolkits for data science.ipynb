{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Python Reference Codes\n",
    "\n",
    "Examples based on Titanic dataset (from Seaborn)\n",
    "\n",
    "### Table of Contents\n",
    "(1) [Importing / Exporting Data](#part1)   \n",
    "(2) [Data Exploration](#part2)  \n",
    "(3) [Data Manipulation / Transformation](#part3)  \n",
    "(4) [Visualization](#part4)  \n",
    "(5) [Data Analysis and Statistics](#part5)  \n",
    "(6) [Miscellaneous](#part6)\n",
    "\n",
    "First importing all the necessary libraries and dataset <b>df</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.get_dataset_names()\n",
    "df = seaborn.load_dataset('titanic')\n",
    "\n",
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "# Expanding screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"part1\"></a>\n",
    "### (1) Importing / Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV and specifying index_col to set which column to be the index column\n",
    "df = pd.read_csv('datasets/data-titanic.csv')\n",
    "df = pd.read_csv('datasets/data-titanic.csv', index_col=\"age\")\n",
    "df = pd.read_excel('datasets/data-titanic.xlsx')\n",
    "\n",
    "# Exporting dataset\n",
    "df.to_csv('datasets/data-titanic.csv')\n",
    "df.to_excel('datasets/data-titanic.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"part2\"></a>\n",
    "### (2) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve column (3 different ways to do it)\n",
    "df[\"age\"]\n",
    "df.loc[:,\"age\"]\n",
    "df.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe dataset (numeric columns) and Printing without limit/display constraints\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all values of each column\n",
    "print(df.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General info of dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of all values of each numeric column\n",
    "print(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe summary stats for only certain columns\n",
    "print(df[['age','fare','pclass']].describe())  \n",
    "# Note double square brackets to create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary stats but exclude data column of certain dtype e.g. object type\n",
    "print(df.describe(exclude = [\"object\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print datatypes\n",
    "columns = ['age', 'who', 'pclass']\n",
    "print(df[columns].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find datatype of each column (Creating a new column called Data Type)\n",
    "data_types = pd.DataFrame(df.dtypes, columns=['Data Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data type of column\n",
    "# Changing object to category dtype helps reduce memory usage\n",
    "df.who = df.who.astype('category')\n",
    "\n",
    "df.pclass = df.who.astype('float')\n",
    "\n",
    "df.age = pd.to_numeric(df.age,errors = 'coerce')\n",
    "# Using coerce, the column values will be converted to numbers while \n",
    "# the non-numerics invalid values (such as -) will be converted to NaN. \n",
    "# If we do not input the coerce argument, Python will return an error as\n",
    "# it does not know how to turn the string (such as -) into a numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting values into ordered categories (i.e with ranking)\n",
    "df.pclass = pd.Categorical(df.pclass,categories=[3,2,1], ordered = True) # Ascending order\n",
    "df.pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string to numeric\n",
    "df['fare'] = pd.to_numeric(df['fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency counts\n",
    "df.embarked.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generating frequency table with crosstabs\n",
    "freq_table = pd.crosstab(df.sex, df.pclass)\n",
    "freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return unique value counts with counting of occurences\n",
    "print(df.who.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proportion based on unique counts using normalize = True\n",
    "print(df.who.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns have any null observation at all\n",
    "print(df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of missing null observations by column\n",
    "print(df.isnull().sum())\n",
    "missing_data_counts = pd.DataFrame(df.isnull().sum(), columns=['Missing Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of present observations by column\n",
    "present_data_counts = pd.DataFrame(df.count(), columns=['Present Values'])\n",
    "print(present_data_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique observations for every column\n",
    "unique_value_counts = pd.DataFrame(columns=['Unique Values'])\n",
    "for v in list(df.columns.values):   # This means for every column in the list of columns\n",
    "    unique_value_counts.loc[v] = [df[v].nunique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique values\n",
    "print(df.who.unique()) # List of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values\n",
    "print(df.who.nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a dataframe based on unique last strings in a column\n",
    "def get_unique_last_str(df):\n",
    "    df = df[df.index.isin(df['embark_town'].drop_duplicates(keep='last').index)].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "print(get_unique_last_str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find minimum value for each column\n",
    "minimum_values = pd.DataFrame(columns=['Minimum Values'])\n",
    "for v in list(df.columns.values):\n",
    "    minimum_values.loc[v] = [df[v].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find maximum value for each column\n",
    "maximum_values = pd.DataFrame(columns=['Maximum Values'])\n",
    "for v in list(df.columns.values):\n",
    "    maximum_values.loc[v] = [df[v].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 5 rows with lowest values (Different from using tail())\n",
    "print(df.nsmallest(5, \"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates column value (boolean True/False) based on isin list\n",
    "print(df.age.isin([2,3,22,38])) # Rows with ages stated in the list\n",
    "print(df[df.age.isin([2,3,22,38])])  # Rows with True for the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean based on BOOLEAN values (to get a proportion of Trues)\n",
    "print(df.adult_male.mean())  # Gets proportion of adults who are male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for correlation\n",
    "print(np.corrcoef(df.age.values, df.fare.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby methods\n",
    "print(df.groupby(['who']).age.mean())\n",
    "print(df.groupby(['who']).age.max())\n",
    "print(df.groupby(['who']).deck.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping one column with means\n",
    "df_gender = df.groupby(['sex'])['age', 'fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping multiple columns with means\n",
    "columns = ['age', 'fare']\n",
    "df_gender = df.groupby([\"sex\"])[columns].mean()\n",
    "\n",
    "df_pclass = df.groupby(['pclass'])['age', 'fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting groups (with get_group) after using groupby\n",
    "df_gender = df.groupby(['sex'])\n",
    "df_gender.get_group('male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting single value (based on loc and/or max)\n",
    "df.loc[3,'age'].max()\n",
    "df.loc[4,'fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using assert to confirm hypothesis\n",
    "assert df.who.dtypes == np.object # If no error msg, it means assertion is correct\n",
    "assert df.age.dtypes == np.object # This returns assertion error ie. statement is false\n",
    "# Object means that the values are stored as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values with assert\n",
    "assert pd.notnull(df.alone).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative counts and cumulative sums\n",
    "df['running_sales_total'] = df.fare.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum can also be used with groupby\n",
    "df['running_sales_by_gender'] = df.groupby('sex').fare.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative count\n",
    "df['count_by_gender'] = df.groupby('sex').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get discrete intervals with cut i.e. Convert continuous data into categorical\n",
    "def get_discrete_intervals_from_values(df):\n",
    "    df['age_class'] = pd.cut(df['age'], \n",
    "                          bins=[-1,18,40,65,999], \n",
    "                          labels=['young','adult','old','very old'])\n",
    "    return df\n",
    "df = get_discrete_intervals_from_values(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple version of cut\n",
    "df['agecut'] = pd.cut(df.age, bins = [0,18,25,99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of qcut to specify no. of bins (automatically creates quantiles of approximately equal \n",
    "# sample size)\n",
    "df['agebins'] = pd.qcut(df.age, q=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"part3\"></a>\n",
    "### (3) Data Manipulation and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting elements from list\n",
    "areas = [1.23,1.43,1.44,1.75,1.26]\n",
    "del(areas[1])\n",
    "del(areas[-4:-2])\n",
    "\n",
    "# Delete by item value\n",
    "areas.remove(1.23)\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing as column(s) as Series (single brackets) or DataFrame (double brackets)\n",
    "print(df[\"pclass\"])   # Series\n",
    "print(df.loc[:][\"age\"])   # Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating subset dataframe\n",
    "print(df[[\"pclass\"]])   # DataFrame\n",
    "print(df.iloc[[1,6]])   # DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use loc only if index has labels\n",
    "print(df.iloc[[23,35], [3,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering and Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering and printing specific rows\n",
    "print(df.iloc[0]) # First row\n",
    "df.loc[df['age'] == df['age'].max()]  # Row with max value\n",
    "df[df.age == 22].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering based on multiple conditions\n",
    "df2 = df[(df.age == 29.0) & (df.pclass == 1)]  # using AND operator\n",
    "df2 = df[(df.age == 29.0) | (df.pclass == 1)]  # Using OR operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering based on a range/criteria of values using np.logical\n",
    "df_age = df['age']\n",
    "between = np.logical_and(df_age > 12, df_age < 31)  # or can use np.logical_or\n",
    "medium = df_age[between]\n",
    "print(medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting and Slicing columns\n",
    "df_age_fare_survival = df[['age', 'fare', 'survived']]  #Subsetted dataframe by columns\n",
    "df_survived_pclass_sex = df.loc[:,'survived':'sex']  # Alternative slicing by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting by rows based on index\n",
    "df_index10to50 = df[10:51]  \n",
    "df_index50to10 = df[51:10:-1]  # Reverse order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing null and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with NaN\n",
    "columns = df.columns.values\n",
    "for column in columns:\n",
    "    df.loc[df[column] == 'C', column] = np.nan  # Use C value as an example only\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN (null) values with zero\n",
    "df['age'] = df.age.fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with some other value\n",
    "df.age.isna().sum()  # Number of NaN originally\n",
    "df['age'] = df['age'].fillna(df.age.mean())   # Imputing NaN with mean value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all rows with missing values in ANY column\n",
    "df_dropped = df.dropna(axis = 0)\n",
    "print(df_dropped.shape)      #Output 891 rows decreased to 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with missing value in a SPECIFIC column\n",
    "df_dropped = df[np.isfinite(df['age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all rows with missing values across ALL columns\n",
    "df_dropped = df.dropna(how='all')\n",
    "print(df_dropped.shape)\n",
    "\n",
    "df.dropna(subset=['age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns and rows\n",
    "df = df.drop('alive', axis=1) # Drop column i.e Axis 1\n",
    "df = df.drop(3, axis=0) # Drop row i.e. Axis 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_drop = ['age','pclass','survived','who']\n",
    "df_dropped = df.drop(list_to_drop, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns where there are less than 800 NON-missing values (Based on thresh argument)\n",
    "df_dropped = df.dropna(thresh=800, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows in a dataframe based on indexes of another dataframe (Axis = 0 means Row)\n",
    "df_dropped = df.drop(df_duplicate.index.values, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "df = df.drop_duplicates() # 891 rows down to 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation with sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer= SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:,1:3])\n",
    "X[:,1:3]=imputer.transform(X[:,1:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all rows (Range 0 to full number of rows) of price column into single value\n",
    "for i in range(0, len(df.index)):\n",
    "    df.loc[i,'age'] = 30  # Change all age to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing only a single value (row index 3 of the age column)\n",
    "df.loc[3,'age'] = 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing summation ACROSS columns for all rows\n",
    "df2 = df[['age','fare']]\n",
    "print(df2.sum(axis = 1))  # Sums the numerical values across columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate/copy dataframe\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column that codes a numerical value for each categorical value of a column\n",
    "# This is done for every row in the df (indicated by for i in range(len(df)))\n",
    "# For this to run, the index needs to be in running sequence without any number missing\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i,'who'] == 'man':\n",
    "        df.loc[i,'man'] = 1\n",
    "    elif df.loc[i,'who'] == 'woman':\n",
    "        df.loc[i,'woman'] = 1\n",
    "    elif df.loc[i,'who'] == 'child':\n",
    "        df.loc[i,'child'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting dummy table (one-hot encoding)\n",
    "df = pd.get_dummies(df,columns = ['sex','alive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recoding in single new column (instead of one-hot coding)\n",
    "def recode_sex(sex):\n",
    "\n",
    "    # Return 0 if gender is 'Female'\n",
    "    if sex == 'female':\n",
    "        return 0\n",
    "    \n",
    "    # Return 1 if gender is 'Male'    \n",
    "    elif sex == 'male':\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df.sex_recoded = df.sex.apply(recode_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in dataframe (with use of lambda function)\n",
    "df['sex'] = df.sex.apply(lambda x: x.replace('female', 'Female'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace characters in a string\n",
    "df = df.sex.str.replace('male','Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column and replacing values with the use of dictionary and mapping function\n",
    "class_to_numeric = {'First':'1st', 'Second':'2nd', 'Third':'3rd'}\n",
    "df['class_num'] = df['class'].map(class_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using map on multiple columns with applymap\n",
    "mapping = {1:'Yes',0:'No'}\n",
    "cols = ['survived','parch']\n",
    "df[cols] = df[cols].applymap(mapping.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming all column names based on mapping\n",
    "df = df.rename(columns = mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using apply\n",
    "df[\"CLASS\"] = df[\"class\"].apply(str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging, Concatenating and Appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending multiple datasets (of same shape)\n",
    "df_duplicate = df.append(df).append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending flat files in bulk (Alternative method to the above)\n",
    "filenames = ['titanic.csv', 'titanic.csv', 'titanic.csv']\n",
    "\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating dataframes row-wise (Similar to append)\n",
    "df2 = pd.concat([df,df,df], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating dataframes COLUMN-wise\n",
    "df2 = pd.concat([df,df,df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes\n",
    "df2 = pd.merge(left=df, right=df, on = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging on columns with non-matching labels\n",
    "df2 = pd.merge(df, df, left_on = 'age', right_on = 'age') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging on multiple columns\n",
    "df2 = pd.merge(df, df, on = ['age', 'sex', 'embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join\n",
    "df_left = pd.merge(df, df, how = 'left', on = ['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging and concatenating multiple files e.g. csv\n",
    "import glob\n",
    "import os\n",
    "os.chdir(\"C:/Users/klty0/Desktop/airline delay and cancellation\")\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')\n",
    "#encoding = ‘utf-8-sig’ is added to overcome the issue when exporting ‘Non-English’ languages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching and Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for a string using contains method\n",
    "df_town = df[df.embark_town.str.contains('town',na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of regular expression (regex) to find pattern\n",
    "pattern = '^[A-Za-z\\.\\s]*$'\n",
    "boolean_vector = df.who.str.contains(pattern)\n",
    "df_pattern = df.loc[boolean_vector]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoting, Melting and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting index (can be single level or multi-level) and selecting index\n",
    "df2 = df.set_index(['age','sex'])\n",
    "df2 = df.set_index(['age'])\n",
    "df2 = df2.sort_index()\n",
    "print(df2.loc[29.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting with pivot table\n",
    "df_pivot = df.pivot_table(index='embark_town', columns = 'sex', values = 'age', \n",
    "                          aggfunc = np.mean)\n",
    "\n",
    "df_pivot = df.pivot_table(index='embark_town', columns = 'sex', \n",
    "                          values = ['age','fare'], \n",
    "                          aggfunc = {'age':np.mean, 'fare':np.sum})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstacking - Equivalent to changing a row index into a column index for a multi-index\n",
    "# Meaning that if you have a Multi-indexed Series, you can convert it into a dataframe\n",
    "# using Unstack\n",
    "df2 = df.set_index(['embark_town','sex'])\n",
    "df_unstack = df2.unstack(level = 'embark_town')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking - Equivalent to changing a column index into a row index for a multi-index\n",
    "df_stack = df_unstack.stack(level = 'sex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting dataframes\n",
    "df_melt = pd.melt(frame = df, id_vars=['survived','sex','embarked'])\n",
    "# More info on melting & pivoting in Chapter 7-2. Tidying data for analysis and\n",
    "# Chapter 9-3.Rearranging and reshaping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"part4\"></a>\n",
    "### (4) Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot\n",
    "df.plot(x='pclass', y='fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "df.age.plot('hist')\n",
    "df.age.plot('hist', bins = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling with log scales\n",
    "df['age'].plot(kind='hist', rot=70, logx=True, logy=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating probability density function - pdf (General code template)\n",
    "mu = 200\n",
    "sigma = 15\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma)\n",
    "plt.plot(x, st.norm.pdf(x, mu, sigma))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplots and setting the y-axis limits\n",
    "df.boxplot(column='age', by='pclass').set_ylim(0,100)\n",
    "df.boxplot(column='age', by='pclass', rot=90) # Rotates x axis labels\n",
    "df.boxplot(column = ['age','sex','pclass']) # Selected columns only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating scatterplot\n",
    "df.plot(kind='scatter', x='age', y='fare', rot=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating barplot with x labels (x ticks)\n",
    "df.plot(kind = 'bar')\n",
    "df.sort_values.plot(kind = 'bar', stacked = True) # Sort, then show stacked bar plot\n",
    "df.plot(kind = 'barh') # Horizontal barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting x ticks labels\n",
    "plt.xticks(\n",
    "   np.arange(len(df.age)),   #Returns evenly spaced values within given interval\n",
    "   df.index,    #Labeling of xticks with major_category\n",
    "   rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting with subplots\n",
    "df.plot(kind = 'bar', subplots = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying x and y axes and limits\n",
    "plt.xlabel('Life Expectancy by Country in 1800')\n",
    "plt.ylabel('Life Expectancy by Country in 1899')\n",
    "\n",
    "plt.xlim(20, 55)\n",
    "plt.ylim(20, 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"part5\"></a>\n",
    "### (5) Data Analysis and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis with z-score\n",
    "from scipy.stats import zscore \n",
    "fare_zscore = zscore(df.fare)\n",
    "df['fare_zscore'] = fare_zscore # Assigning the numpy array as a new dataframe column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"part6\"></a>\n",
    "### (6) Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives numbers 0 to 9\n",
    "print(list(range(10)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reveal all columns of the dataframe in the IPython shell\n",
    "pd.set_option('display.max_columns', 100) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
